"""PyTorch Ã— Flower ì—°í•©í•™ìŠµ: GPU + tqdm ì§€ì› ë²„ì „.

- ê° ê°€ìƒ í´ë¼ì´ì–¸íŠ¸ë§ˆë‹¤ `ray.get_gpu_ids()`ë¡œ GPU ì§€ì •
- Ray worker stdout â†” tqdm ì¶©ëŒ í•´ê²°: worker ë‚´ ì§„í–‰ë°” ìë™ ë¹„í™œì„±í™”
- FedBN, FedProx, ê¸°ë³¸ FedAvg ëª¨ë‘ ì§€ì›
"""
from __future__ import annotations

import json
import logging
import os
from pathlib import Path
from typing import Dict, List, Sequence

import flwr as fl
import ray  # GPU ID í™•ì¸ìš©
import torch
from flwr.client import NumPyClient
from flwr.common import Context
from omegaconf import DictConfig
from tqdm.auto import tqdm as _tqdm  # Jupyter/CLI ëª¨ë‘ ëŒ€ì‘

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tqdm â†’ Rayâ€‘safe wrapper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_IS_RAY_WORKER = "RAY_WORKER_ID" in os.environ  # Ray worker ì—¬ë¶€ íŒë³„

def tqdm(*args, **kwargs):  # noqa: N802  (snake_case ìœ ì§€)
    """Return a tqdm iterator that **disables itself** inside Ray workers.

    Rayê°€ `\r` ì»¤ì„œ ì´ë™ ë¬¸ìë¥¼ `\n`(ê°œí–‰)ìœ¼ë¡œ ë°”ê¿” ë“œë¼ì´ë²„ì— ì „ë‹¬í•˜ëŠ” ë°”ëŒì—
    ì§„í–‰ë°”ê°€ *ë§¤ ì—…ë°ì´íŠ¸ë§ˆë‹¤ í•œ ì¤„ì”©* ìŒ“ì´ëŠ” ë¬¸ì œë¥¼ ë°©ì§€í•œë‹¤.
    """
    kwargs["disable"] = _IS_RAY_WORKER or kwargs.get("disable", False)
    return _tqdm(*args, **kwargs)

# tqdm.write ê·¸ëŒ€ë¡œ ì“°ë„ë¡ ë³„ì¹­ ìœ ì§€
tqdm.write = _tqdm.write  # type: ignore[attr-defined]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¡œê¹… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
)
log = logging.getLogger("train")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‚¬ìš©ì ëª¨ë“ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê²½ë¡œ: project_root/train/{loader,models,strategies}.py
from train.loader import get_dataloaders_from_split
from train.models import init_net
from train.strategies import get_strategy

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì „ì—­ ì¥ì¹˜ (ë°±ì—…) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _is_bn(name: str) -> bool:
    """BatchNorm ê³„ì¸µ íŒŒë¼ë¯¸í„° ì—¬ë¶€ (FedBNì—ì„œ ì‚¬ìš©)."""
    return any(k in name for k in (".running_mean", ".running_var", ".num_batches_tracked"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Flower í´ë¼ì´ì–¸íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class FederatedClient(NumPyClient):
    """Flower NumPyClient with GPU awareness & tqdm logging."""

    def __init__(
        self,
        model: torch.nn.Module,
        train_loader: torch.utils.data.DataLoader,
        test_loader: torch.utils.data.DataLoader,
        cfg: DictConfig,
    ) -> None:
        gpu_ids: Sequence[int] = ray.get_gpu_ids()  # ex) [0]
        if gpu_ids:
            torch.cuda.set_device(int(gpu_ids[0]))
            self.device = torch.device("cuda")
            log.info(f"Client assigned GPU {gpu_ids[0]}")
        else:
            self.device = torch.device("cpu")
            log.info("Client using CPU")

        self.model = model.to(self.device)
        self.train_loader = train_loader
        self.test_loader = test_loader
        self.cfg = cfg
        self._local_bn_params: Dict[str, torch.Tensor] = {}

    # ---------------- Flower í•„ìˆ˜ ë©”ì„œë“œ ----------------
    def get_parameters(self, config=None):  # noqa: D401  (Flower ì‹œê·¸ë‹ˆì²˜)
        # state_dict()ëŠ” OrderedDict ë³´ì¥ â†’ key ìˆœì„œ ìœ ì§€
        return [p.detach().cpu().numpy() for p in self.model.state_dict().values()]

    def set_parameters(self, params: List, config=None):  # noqa: D401
        state = self.model.state_dict()
        is_fedbn = self.cfg.train.strategy.lower() == "fedbn"
        for name, tensor in zip(state.keys(), params):
            if is_fedbn and _is_bn(name):  # FedBN â†’ BN ë¡œì»¬ ìœ ì§€
                continue
            state[name] = torch.tensor(tensor, device=self.device)
        self.model.load_state_dict(state, strict=True)

        # FedBN: ë¡œì»¬ BN íŒŒë¼ë¯¸í„° ìºì‹± (í–¥í›„ ë³µì›ìš©)
        if is_fedbn:
            for n, p in state.items():
                if _is_bn(n):
                    self._local_bn_params[n] = p.clone()

    # ---------------- Fit ----------------
    def fit(self, params, config=None):  # noqa: D401
        self.set_parameters(params)
        self.model.train()

        optim = torch.optim.Adam(self.model.parameters(), lr=self.cfg.train.lr)
        criterion = torch.nn.CrossEntropyLoss()
        mu = float(config.get("mu", 0.0))  # FedProx Î¼ (0ì´ë©´ off)
        global_params = [p.detach().clone() for p in self.model.parameters()]

        epochs = self.cfg.train.local_epochs
        cid = config.get("partition_id", 0) if config else 0  # í´ë¼ì´ì–¸íŠ¸ ID

        # ì‹œì‘ ë¡œê·¸ ì¶œë ¥
        log.info(f"ğŸŸ¢ Client {cid} starting {epochs} local epochs")

        total_loss = 0.0
        for ep in range(epochs):
            pbar = tqdm(
                self.train_loader,
                desc=f"C{cid}-E{ep + 1}/{epochs}",
                leave=False,
                dynamic_ncols=True,
                mininterval=15.0,  # ì—…ë°ì´íŠ¸ ë¹ˆë„ ë” ì¤„ì„
                disable=_IS_RAY_WORKER,  # Ray workerì—ì„œ ì§„í–‰ë°” ë¹„í™œì„±í™”
            )
            running_loss = 0.0
            for step, (x, y) in enumerate(pbar):
                x, y = x.to(self.device), y.to(self.device)
                optim.zero_grad()

                # forward
                logits = self.model(x)
                loss = criterion(logits, y)

                # FedProx ê·œì œí•­
                if mu > 0:
                    prox = sum(
                        (w - w0).pow(2).sum()
                        for w, w0 in zip(self.model.parameters(), global_params)
                    )
                    loss = loss + 0.5 * mu * prox

                # backward + step
                loss.backward()
                optim.step()

                running_loss += loss.item()
                total_loss += loss.item()
                # ì§„í–‰ë°” ì—…ë°ì´íŠ¸ (20 stepë§ˆë‹¤)
                if step % 20 == 0:
                    pbar.set_postfix(loss=f"{running_loss / (step + 1):.4f}", refresh=False)

        # ì™„ë£Œ ë¡œê·¸ ì¶œë ¥
        avg_loss = total_loss / (epochs * len(self.train_loader))
        log.info(f"ğŸ”µ Client {cid} completed training - Average Loss: {avg_loss:.4f}")

        # í•™ìŠµ ì™„ë£Œ â†’ íŒŒë¼ë¯¸í„° ë°˜í™˜
        return self.get_parameters(config), len(self.train_loader.dataset), {}

    # ---------------- Evaluate ----------------
    def evaluate(self, params, config=None):  # noqa: D401
        self.set_parameters(params)
        self.model.eval()
        criterion = torch.nn.CrossEntropyLoss()
        total, correct, loss_sum = 0, 0, 0.0

        with torch.no_grad():
            for x, y in tqdm(self.test_loader, desc="Eval", leave=False, disable=_IS_RAY_WORKER):
                x, y = x.to(self.device), y.to(self.device)
                logits = self.model(x)
                loss_sum += criterion(logits, y).item() * x.size(0)
                correct += (logits.argmax(1) == y).sum().item()
                total += y.size(0)

        return loss_sum / total, total, {"accuracy": correct / total}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹œë®¬ë ˆì´ì…˜ ëŸ°ì²˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_federated_training(cfg: DictConfig):
    """Hydra DictConfig â†’ Flower Simulation ì‹¤í–‰."""

    # 1) í´ë¼ì´ì–¸íŠ¸ë³„ ì¸ë±ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸°
    split_path = Path(cfg.dataset.split_path)
    with split_path.open("r", encoding="utf-8") as f:
        client_splits = json.load(f)["splits"]

    data_root = Path(cfg.dataset.root)

    # 2) Flower í´ë¼ì´ì–¸íŠ¸ íŒ©í† ë¦¬
    def client_fn(context: Context):
        # Flower ìµœì‹  ë²„ì „: Context ê°ì²´ ì‚¬ìš©
        part_id = int(context.node_config["partition-id"])
        key = f"client_{part_id}"
        if key not in client_splits:
            raise KeyError(f"Split indices for {key} not found in {split_path}")

        log.info(f"Creating client {part_id} with {len(client_splits[key])} samples")

        # ë°ì´í„°ë¡œë” ìƒì„±
        train_loader, test_loader = get_dataloaders_from_split(
            client_id=part_id,
            split_indices=client_splits[key],
            data_root=data_root,
            batch_size=cfg.train.batch_size,
            dataset_name=cfg.dataset.name,
        )

        # ëª¨ë¸ ì´ˆê¸°í™”
        model = init_net(cfg.model.name, cfg.model.output_dim)
        log.info(f"Client {part_id} model initialized on {DEFAULT_DEVICE}")
        numpy_client = FederatedClient(model, train_loader, test_loader, cfg)
        return numpy_client.to_client()  # NumPyClientë¥¼ Clientë¡œ ë³€í™˜

    # 3) ì „ëµ ê°ì²´ ìƒì„± (FedAvg / FedProx / FedBN)
    strategy = get_strategy(cfg)

    # 4) Flower ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
    log.info("Flower simulation starting â€¦")
    history = fl.simulation.start_simulation(
        client_fn=client_fn,
        num_clients=len(client_splits),
        client_resources={"num_gpus": 1, "num_cpus": 1},
        config=fl.server.ServerConfig(num_rounds=cfg.train.rounds),
        strategy=strategy,
    )
    log.info("Simulation finished")

    try:
        import pandas as pd
        import matplotlib.pyplot as plt

        losses = history.losses_centralized
        metrics = history.metrics_centralized.get("accuracy", [])

        rounds = [r for r, _ in losses]
        loss_vals = [l for _, l in losses]
        acc_vals = [acc for _, acc in metrics] if metrics else [None] * len(losses)

        history_df = pd.DataFrame({
            "round": rounds,
            "loss": loss_vals,
            "accuracy": acc_vals,
        })

        out_dir = Path("results") / f"fl_{cfg.train.strategy.lower()}"
        out_dir.mkdir(parents=True, exist_ok=True)

        history_path = out_dir / "history.csv"

        history_df.to_csv(history_path, index=False)
        log.info(f"ğŸ“Š History saved to {history_path.resolve()}")
    except Exception as e:
        log.warning(f"Warning: {str(e)}")

    return history
